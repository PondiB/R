---
title: "Bush density mapping"
author: CIAT
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
fontsize: 11pt
geometry: margin=1in
output:
  pdf_document:
    fig_width: 7
    fig_height: 5
    fig_caption: true
---

### Objectives
This manual will help you calculate bush density using count data with ndvi and 
crown cover data as covariates. At the end of this session, you will be able to:

1.  Import excel data into R.
2.  Import raster data into R.
3.  Convert data from excel to ESRI point shapefile.
4.  Use the point and raster data to construct a random forest model.
5.  Use the RF model to predict bush density.
6.  Test model accuracy.

Download the sample dataset we will use in this session from this link 
<https://drive.google.com/open?id=0B_Gkb_0tNKkQcGZGc1ZWRnpZc0U>

Before you start this session, it is important you have (i) the latest 
[R software](https://cran.r-project.org/bin/windows/base/) and (ii) 
[Rstudio](https://www.rstudio.com/) installed in your computer.

Start the session but first clear your work space.
```{r}
rm(list = ls(all = TRUE))
```


```{r echo=FALSE}
library("knitr")
opts_knit$set(root.dir= "C:/LDN_Workshop/Sample_dataset/Bush_Density_Mapping")
```

```{r setup, include=FALSE, cache=FALSE}
muffleError <- function(x,options) {}
knit_hooks$set(error=muffleError)
```

To enable us reproduce the results next time, let's set the seed.
```{r}
set.seed(500)
```

Set the start of data processing.
```{r}
startTime <- Sys.time()
cat("Start time", format(startTime),"\n")
```

Set working directory.
```{r}
setwd("C:/LDN_Workshop/Sample_dataset/Bush_Density_Mapping")
```

List down the packages to be used in this session. Packages will be 
installed if not already installed. They will then be loaded into the session.
```{r}
.packages = c("sp","rgdal","raster","randomForest","plyr","xlsx","xlsxjars",
              "dplyr","caret","car", "e1071","snow")
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
lapply(.packages, require, character.only=TRUE)
```

To get help on the functions and data sets in R, use `help()` or `?`. 
For example, to view the help file for the `calc` function, type one of the 
following:
```{r help, eval=FALSE}
help(calc)
?calc
```

###Reading your data

Read in data from excel sheet
```{r}
BushData <- read.xlsx("Field_data/Otji_BD_Sampling_Points.xlsx", sheetName = 
                        "Sheet1", header=TRUE)
```

Calculate values by finding the median in crown cover and mean of values for 
counts.Note that 1 plot = 0.01 ha; 4 plots = 0.04 ha
```{r}
BushData$shrubs_less_1.5 <- apply(BushData[,8:11], 1, sum, na.rm=TRUE)
BushData$shrubs_more_1.5_no_stem <- apply(BushData[,16:19], 1, sum, na.rm=TRUE)
BushData$shrubs_more_1.5_stem <- apply(BushData[,24:27], 1, sum, na.rm=TRUE)
```

Create new 'data.frame' with the columns you need
```{r}
BushData_clean<-BushData[,c("Waypoint_No","Latitude","Longitude",
                            "shrubs_less_1.5","shrubs_more_1.5_no_stem",
                            "shrubs_more_1.5_stem")]
```

Add two new columns of shrubs more than 1.5 and all shrubs in general
```{r}
BushData_clean$shrubs_more_1.5 <- apply(BushData_clean[,5:6], 1, sum, 
                                        na.rm=TRUE)
BushData_clean$shrubs_all <- apply(BushData_clean[,4:6], 1, sum, na.rm=TRUE)
```

Round columns.
```{r}
BushData_clean<-BushData_clean %>% 
  mutate_each(funs(round(.,0)), shrubs_less_1.5, shrubs_more_1.5_no_stem, 
              shrubs_more_1.5_stem, shrubs_more_1.5, shrubs_all)
```

Remove all NAs.
```{r}
BushData_clean<-BushData_clean[complete.cases(BushData_clean),]
```

Export data to .csv
```{r}
write.csv(BushData_clean, file = "Otji_BushData_trainData.csv",row.names=FALSE)
```

Get long and lat from your data.frame. Make sure that the order is in lon/lat.
Convert the dataraframe into a spatial point dataframe.
```{r}
xy <- BushData_clean[,c(3,2)]
trainDatageo <- SpatialPointsDataFrame(coords = xy, data = BushData_clean,
                                    proj4string = CRS("+proj=longlat 
                                                      +datum=WGS84"))
trainData <- spTransform(trainDatageo, CRS('+proj=utm +zone=33 +south 
                                           +datum=WGS84'))
```

Let's do some background checking of the field names and rename trainData fields
```{r}
names(trainData)
names(trainData) <- c("Waypoint_No","Latitude","Longitude","shrubs_less_1.5",
                      "shrubs_more_1.5_no_stem", "shrubs_more_1.5_stem", 
                      "shrubs_more_1.5", "shrubs_all")
```

Import the rest of input data
```{r}
rasList <- list.files("Raster_data/", pattern = ".tif$", full.names = TRUE)
```

Create a raster stack and rename the contents
```{r}
rstack <- stack(rasList)
names(rstack) <- c("crown_cover","NDVI","band2","band3","band4","band5",
                   "band6","band7")
```

Note that we are only calculating bush density in the bush area LULC catageory.
Import the bush area mask
```{r}
Otjo_BushArea <- raster("Raster_data/Other_data/Otji_BushArea_2016.tif")
```

Set extent of the training data to match covs
```{r}
trainData@bbox <- bbox(Otjo_BushArea)
```

Plot the points on top of `layer 3` of the raster stack
```{r}
plot(rstack[[3]])
plot(trainData, add=TRUE, col = "red", pch = 3)
```

Mask, read and stack the covariates.
```{r}
covs <- mask(rstack, Otjo_BushArea)
```

Assign raster values to the training data.
```{r}
v<-as.data.frame(extract(covs,trainData))
trainData@data=data.frame(trainData@data, v[match(rownames(trainData@data),
                                                  rownames(v)),])
```

Rename fields in the training dataset, remove NAs and write the dataset as a 
.csv
```{r}
names(trainData) <- c("waypoint_no","latitude","longitude","shrubs_less1.5",
                      "shrubs_more1.5_no_stem","shrubs_more1.5_stem",
                      "shrubs_more1.5", "shrubs_all", "crown_cover","NDVI",
                      "band2","band3","band4","band5","band6","band7")
trainData@data<-trainData@data[complete.cases(trainData@data),]
write.csv(trainData@data, file = "Otji_MF_trainData.csv",row.names=FALSE)
````

Let's generate a plot of NDVI versus shrubs and add the R squared value on 
the plot.
```{r}
with(trainData@data, plot(shrubs_less1.5,NDVI, 
                          xlab="Shrubs <1.5m", ylab="NDVI", 
                          main="Plot of NDVI versus Shrubs"))
abline(fit <- lm(NDVI~shrubs_less1.5, data = trainData@data), col='red')
legend("topright", bty="n", legend=paste("R2 =", 
                                         format(summary(fit)$r.squared, 
                                                digits=4)))
```

###Fitting the Random Forest regression models

You can now fit the models using the 'train' function from the 'caret' package. 
i.e. Specify the model as a formula with the dependent variable 
(i.e., count of shrubs).

Use [Bootstrap resampling](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) 
method to estimate model accuracy. This method involves taking random samples 
from the dataset (with re-selection) against which to evaluate the model. In 
aggregate, the results provide an indication of the variance of the models 
performance.
```{r}
tcontrol1 <- trainControl(method="boot", number=100)
model1 <- train(shrubs_less1.5~crown_cover+NDVI,method='rf', 
                trControl = tcontrol1, data=trainData@data)
```

```{r}
tcontrol3 <- trainControl(method="boot", number=100)
model3 <- train(shrubs_all~crown_cover+NDVI,method='rf',
                trControl = tcontrol3, data=trainData@data)
```

Next, before you predict the models, you can print out the 
[RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) and 
[Rsquared](https://en.wikipedia.org/wiki/Coefficient_of_determination) 
. R squared is a number that indicates the proportion of the 
variance in the dependent variable that is predictable from the independent 
variable.
```{r}
print(model1)
print(model3)
```

Use the 'predict' command to make rasters with predictions from the fitted 
models. To speed up computations use the 'clusterR' function from the 'raster' 
package which supports multi-core computing for functions such as predict 
(NB: install 'snow' package).
```{r}
beginCluster()
prediction1 <- clusterR(covs, raster::predict, args = list(model = model1))
prediction3 <- clusterR(covs, raster::predict, args = list(model = model3))
endCluster()
```

Compute the density for shrubs above 1.5m. We can do this by substracting 
shrubs less than 1.5m from all shrubs.
```{r}
prediction2 <- prediction3 - prediction1
```

Multiply the output rasters by 25 to convert the units from shrubs/0.04ha to 
shrubs/1ha, round raster values to whole numbers and save the predicted 
images as GeoTIFFs.
```{r}
prediction1<-round(prediction1*25, digits = 0)
prediction2<-round(prediction2*25, digits = 0)
prediction3<-round(prediction3*25, digits = 0)
writeRaster(prediction1, "otji_bd1.tif", overwrite=TRUE)
writeRaster(prediction2, "otji_bd2.tif", overwrite=TRUE)
writeRaster(prediction3, "otji_bd3.tif", overwrite=TRUE)
```

### Results

Plot the three maps.
```{r}
plot(prediction1, main="Density for shrubs <1.5m", axes=FALSE)
plot(prediction2, main="Density for shrubs >1.5m", axes=FALSE)
plot(prediction3, main="Density for shrubs", axes=FALSE)
```

Finally, check the amount of time you spent conducting this analysis
```{r}
timeDiff <- Sys.time() - startTime
cat("\nProcessing time", format(timeDiff), "\n")
```
