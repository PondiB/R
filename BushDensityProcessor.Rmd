---
title: "Bush density mapping"
author: CIAT
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
fontsize: 11pt
geometry: margin=1in
output:
  pdf_document:
    fig_width: 7
    fig_height: 5
    fig_caption: true
---

```{r echo=FALSE}
#Bush density mapping
#John Mutua, CIAT
```

### Objectives
This manual will help you calculate bush density using count data with ndvi and 
crown cover data as covariates. At the end of this session, you will be able to:

1.  Import excel data into R.
2.  Import raster data into R.
3.  Convert data from excel to ESRI point shapefile.
4.  Use the point and raster data to construct a random forest model.
5.  Use the RF model to predict bush density.
6.  Test model accuracy.

Before you start this session, it is important you have (i) the latest 
[R software](https://cran.r-project.org/bin/windows/base/) and (ii) 
[Rstudio](https://www.rstudio.com/) installed in your computer.

Start the session but first clear your work space.
```{r}
#clear your work space
rm(list = ls(all = TRUE))
```


```{r echo=FALSE}
library("knitr")
opts_knit$set(root.dir= "C:/LDN_Workshop/Sample_dataset/Bush_Density_Mapping")
```

```{r setup, echo=FALSE, include=FALSE, cache=FALSE}
muffleError <- function(x,options) {}
knit_hooks$set(error=muffleError)
```

To enable us reproduce the results next time, let's set the random seed.
```{r}
#set the random seed
set.seed(211134)
```

Set the start of data processing.
```{r}
#set the start of data processing
startTime <- Sys.time()
cat("Start time", format(startTime),"\n")
```

Set working directory.
```{r}
#set working directory
setwd("C:/LDN_Workshop/Sample_dataset/Bush_Density_Mapping")
```

List down the packages to be used in this session. Packages will be 
installed if not already installed. They will then be loaded into the session.
```{r}
#load packages
.packages = c("sp","rgdal","raster","randomForest","plyr","xlsx","xlsxjars",
              "dplyr","caret","car", "e1071","snow")
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
lapply(.packages, require, character.only=TRUE)
```

To get help on the functions and data sets in R, use `help()` or `?`. 
For example, to view the help file for the `calc` function, type one of the 
following:
```{r help, eval=FALSE}
#this is how you get more help on functions
help(calc)
?calc
```

###Reading your data

Read in data from excel sheet
```{r}
#read in data from excel sheet
raw.d <- read.xlsx("Field_data/Otji_BD_Sampling_Points.xlsx", sheetName = 
                        "Sheet1", header=TRUE)
```

Calculate values by finding the median in crown cover and mean of values for 
counts.Note that 1 plot = 0.01 ha; 4 plots = 0.04 ha
```{r}
#calculate values
raw.d$shrubs_less_1.5 <- apply(raw.d[,8:11], 1, sum, na.rm=TRUE)
raw.d$shrubs_more_1.5_no_stem <- apply(raw.d[,16:19], 1, sum, na.rm=TRUE)
raw.d$shrubs_more_1.5_stem <- apply(raw.d[,24:27], 1, sum, na.rm=TRUE)
```

Create new 'data.frame' with the columns you need
```{r}
#create new dataframe with columns you need
raw.d<-raw.d[,c("Waypoint_No","Latitude","Longitude",
                            "shrubs_less_1.5","shrubs_more_1.5_no_stem",
                            "shrubs_more_1.5_stem")]
```

Add two new columns of shrubs more than 1.5 and all shrubs in general
```{r}
#add two new columns of shrubs > 1.5 and all shrubs in general
raw.d$shrubs_more_1.5 <- apply(raw.d[,5:6], 1, sum, na.rm=TRUE)
raw.d$shrubs_all <- apply(raw.d[,4:6], 1, sum, na.rm=TRUE)
```

Round columns and create new 'data.frame with the columns you need.
```{r}
#round columns
raw.d<-raw.d %>% 
  mutate_each(funs(round(.,0)), shrubs_less_1.5, shrubs_more_1.5, 
              shrubs_all)
raw.d<-raw.d[,c("Waypoint_No","Latitude","Longitude","shrubs_less_1.5", 
        "shrubs_more_1.5", "shrubs_all")]
```

Compute shrubs per hectare.
```{r}
#compute shrubs per hectare
raw.d$shrubs_less_1.5 <- raw.d$shrubs_less_1.5*25
raw.d$shrubs_more_1.5 <- raw.d$shrubs_more_1.5*25
raw.d$shrubs_all <- raw.d$shrubs_all*25
```

Remove all NAs.
```{r}
#remove all NAs
raw.d<-raw.d[complete.cases(raw.d),]
```

Plot histograms of the three variables
```{r}
#plot histograms of the three variables
hist(raw.d$shrubs_less_1.5, col = "lightblue", xlab="Count", main="Shrubs, [<1.5]")
hist(raw.d$shrubs_more_1.5, col = "lightblue", xlab="Count", main="Shrubs, [>1.5]")
hist(raw.d$shrubs_all, col = "lightblue", xlab="Count", main="Shrubs, [all]")
```

Export data to .csv
```{r}
#export data to .csv
write.csv(raw.d, file = "Otji_BushData_trainData.csv",row.names=FALSE)
```

Get long and lat from your data.frame. Make sure that the order is in lon/lat.
Convert the dataraframe into a spatial point dataframe.
```{r}
#make shapefiles
xy <- raw.d[,c(3,2)]
trainDatageo <- SpatialPointsDataFrame(coords = xy, data = raw.d,
                                    proj4string = CRS("+proj=longlat 
                                                      +datum=WGS84"))
trainData <- spTransform(trainDatageo, CRS('+proj=utm +zone=33 +south 
                                           +datum=WGS84'))
```

Let's do some background checking of the field names and rename trainData fields
```{r}
#rename fields
names(trainData)
names(trainData) <- c("Waypoint_No","Latitude","Longitude","shrubs_less_1.5",
                      "shrubs_more_1.5", "shrubs_all")
```

Import the rest of input data, stack and rename contents
```{r}
#import the rest of input data, stack and rename contents
r.list<-list.files(".", pattern = ".tif$", full.names = TRUE)
r.stack <- stack(r.list)
names(r.stack) <- c("cc","ndvi","b2","b3","b4","b5","b6","b7")
```

Note that we are only calculating bush density in the bush area LULC catageory.
Import the bush area mask
```{r}
#import the bush area mask
o.mask <- raster("Other_data/Otji_BushArea_2016.tif")
```

Set extent of the training data to match covs
```{r}
#set extent of the training data to match covs
trainData@bbox <- bbox(o.mask )
```

Plot the points on top of `layer 3` of the raster stack
```{r}
#plot the points on top of `layer 3` of the raster stack
plot(r.stack[[3]])
plot(trainData, add=TRUE, col = "red", pch = 3)
```

Mask, read and stack the covariates. Remove NA values 
(otherwise RF cannot predict)
```{r}
#mask and remove NAs in the covariates
covs <- mask(r.stack, o.mask )
covs <- na.omit(covs)
```

Assign raster values to the training data.
```{r}
#assign raster values to the training data
v<-as.data.frame(extract(covs,trainData))
trainData@data=data.frame(trainData@data, v[match(rownames(trainData@data),
                                                  rownames(v)),])
```

Rename fields in the training dataset, remove NAs and write the dataset as a 
.csv
```{r}
#rename fields in the training dataset, remove NAs, write the dataset 
names(trainData) <- c("waypoint.no","lat","lon","shrubs.l1.5","shrubs.g1.5",
                      "shrubs.all","cc","ndvi","b2","b3","b4","b5","b6","b7")
trainData@data<-trainData@data[complete.cases(trainData@data),]
write.csv(trainData@data, file = "Otji_MF_trainData.csv",row.names=FALSE)
```

Compute summary statistics.
```{r}
#compute summary statistics
summary(trainData$shrubs.all)
skewness(trainData$shrubs.all, na.rm=T)
```
QQ plot.
```{r}
#QQ plot
qqnorm(trainData$shrubs.all)
qqline(trainData$shrubs.all)
```
Compute correlation coefficients and plot correlations.
```{r}
#compute correlation coefficients and plot correlations
cor(trainData@data[,4:14])
pairs(trainData@data[,4:14])
```

Correlate count of shrubs with NDVI and Landsat 8 band 2-7.
```{r}
#correlate count of shrubs with NDVI and Landsat 8 band 2-7
cor(trainData@data$shrubs.l1.5,trainData@data$ndvi)
cor(trainData@data$shrubs.all,trainData@data$ndvi)
cor(trainData@data$shrubs.l1.5,trainData@data$cc)
cor(trainData@data$shrubs.all,trainData@data$cc)
cor(trainData@data$shrubs.l1.5,trainData@data$b2)
cor(trainData@data$shrubs.all,trainData@data$b2)
cor(trainData@data$shrubs.l1.5,trainData@data$b3)
cor(trainData@data$shrubs.all,trainData@data$b3)
cor(trainData@data$shrubs.l1.5,trainData@data$b6)
cor(trainData@data$shrubs.all,trainData@data$b6)
cor(trainData@data$shrubs.l1.5,trainData@data$b7)
cor(trainData@data$shrubs.all,trainData@data$b7)
```
Select covariates based on correlation analysis and save as a 'data.frame'.
```{r}
#select covariates based on correlation analysis
d <- trainData@data[,c("waypoint.no","lat","lon","shrubs.l1.5","shrubs.all",
                       "cc", "ndvi")]
names(d)
```

###Fitting the Random Forest regression models

You can now fit the models using the 'train' function from the 'caret' package. 
i.e. Specify the model as a formula with the dependent variable 
(i.e., count of shrubs).

Use [Bootstrap resampling](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) 
method to estimate model accuracy. This method involves taking random samples 
from the dataset (with re-selection) against which to evaluate the model. In 
aggregate, the results provide an indication of the variance of the models 
performance.
```{r}
#fit the model for shrubs <1.5m
tcontrol1 <- trainControl(method="boot", number=100)
model1 <- train(shrubs.l1.5~cc+ndvi,method='rf', trControl = tcontrol1, data=d)
```

```{r}
#fit the model for all shrubs
tcontrol3 <- trainControl(method="boot", number=100)
model3 <- train(shrubs.all~cc+ndvi,method='rf',trControl = tcontrol3, data=d)
```

Next, before you predict the models, you can print out the 
[RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) and 
[Rsquared](https://en.wikipedia.org/wiki/Coefficient_of_determination) 
. R squared is a number that indicates the proportion of the 
variance in the dependent variable that is predictable from the independent 
variable.
```{r}
#print models
print(model1)
print(model3)
```

Use the 'predict' command to make rasters with predictions from the fitted 
models. To speed up computations use the 'clusterR' function from the 'raster' 
package which supports multi-core computing for functions such as predict 
(NB: install 'snow' package).
```{r}
#predict models
beginCluster()
prediction1 <- clusterR(covs, raster::predict, args = list(model = model1))
prediction3 <- clusterR(covs, raster::predict, args = list(model = model3))
endCluster()
```

Compute the density for shrubs above 1.5m. We can do this by substracting 
shrubs less than 1.5m from all shrubs.
```{r}
#compute the density for shrubs >1.5m
prediction2 <- prediction3 - prediction1
```

Round raster values to whole numbers and save the predicted images as GeoTIFFs.
```{r}
#round the numbers
prediction1<-round(prediction1, digits = 0)
prediction2<-round(prediction2, digits = 0)
prediction3<-round(prediction3, digits = 0)
writeRaster(prediction1, "otji_bd1.tif", overwrite=TRUE)
writeRaster(prediction2, "otji_bd2.tif", overwrite=TRUE)
writeRaster(prediction3, "otji_bd3.tif", overwrite=TRUE)
```

### Results

Plot the three maps.
```{r}
#plot the three maps
plot(prediction1, main="Density for shrubs <1.5m", axes=FALSE)
plot(prediction2, main="Density for shrubs >1.5m", axes=FALSE)
plot(prediction3, main="Density for shrubs", axes=FALSE)
```

Finally, check the amount of time you spent conducting this analysis
```{r}
#check amount of time spent
timeDiff <- Sys.time() - startTime
cat("\nProcessing time", format(timeDiff), "\n")
```
